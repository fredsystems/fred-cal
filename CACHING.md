# Caching and Sync Strategy

## Overview

`fred-cal` implements an intelligent caching and synchronization system that:

- **Loads data immediately** from cache on startup (API available instantly)
- **Uses incremental sync** when supported by the server (only fetches changes)
- **Falls back gracefully** to full sync when needed
- **Keeps the API responsive** during sync operations

## How Caching Works

### Cache Location

The cache is stored in platform-specific data directories following XDG standards:

- **Linux**: `~/.local/share/fred-cal/calendar_data.json`
- **macOS**: `~/Library/Application Support/fred-cal/calendar_data.json`
- **Windows**: `%APPDATA%\fred-cal\calendar_data.json`

### Cache Structure

The cache file stores:

- All calendar events (VEVENT components)
- All todos/tasks (VTODO components)
- Last sync timestamp
- Sync tokens per calendar (for incremental updates)

```json
{
  "events": [...],
  "todos": [...],
  "last_sync": "2026-01-03T19:00:00Z",
  "sync_tokens": {
    "/calendars/user/calendar1/": "sync-token-abc123",
    "/calendars/user/calendar2/": "sync-token-def456"
  }
}
```

### Startup Behavior

1. **Load cache immediately** - On startup, `fred-cal` loads the cache from disk
2. **API available instantly** - The API serves cached data while sync runs in background
3. **Initial sync** - Performs first sync (incremental if possible)
4. **Periodic sync** - Background task syncs every 15 minutes

This means your API has **zero downtime** even with large calendars!

## Sync Strategies

### 1. Incremental Sync (WebDAV sync-collection)

**When**: Server supports WebDAV sync-collection protocol

**How it works**:

1. Check if we have a sync token for each calendar
2. Send `sync-collection` REPORT with the sync token
3. Server returns only **changes since last sync**:
   - New events/todos
   - Modified events/todos
   - Deleted events/todos
4. Apply changes to in-memory data
5. Store new sync token for next sync

**Benefits**:

- âš¡ **Fast** - Only transfers changed items
- ğŸ“‰ **Low bandwidth** - Minimal data transfer
- ğŸ¯ **Efficient** - Processes only what changed

**Example log output**:

```shell
INFO Server supports WebDAV sync - using incremental updates
INFO Incremental sync for Personal: +2 events, +1 todos, -0 deleted
INFO Incremental sync for Work: +0 events, +3 todos, -1 deleted
INFO Sync complete: 156 events, 89 todos (from 5 calendars)
```

### 2. Full Sync (calendar-query)

**When**:

- Server doesn't support WebDAV sync
- No sync token available (first sync)
- Sync token is invalid/expired
- Incremental sync fails

**How it works**:

1. Query calendar for all VEVENT components
2. Query calendar for all VTODO components
3. Parse all returned iCalendar data
4. **Replace** all items from that calendar
5. Clear sync token (will try incremental next time)

**Benefits**:

- âœ… **Always works** - Compatible with all CalDAV servers
- ğŸ”„ **Complete refresh** - Ensures data consistency
- ğŸ›¡ï¸ **Fallback safety** - Automatic recovery from sync errors

**Example log output**:

```shell
INFO Server does not support WebDAV sync - using full sync
DEBUG Full sync for Personal: fetched 142 events and 67 todos
INFO Sync complete: 156 events, 89 todos (from 5 calendars)
```

## Performance Characteristics

### Large Calendar Performance

For a calendar with **1000+ events**:

| Operation         | Cold Start | Incremental Sync | Full Sync      |
| ----------------- | ---------- | ---------------- | -------------- |
| **Cache Load**    | ~100ms     | N/A              | N/A            |
| **API Available** | Immediate  | Immediate        | Immediate      |
| **Sync Time**     | -          | ~2-5 seconds     | ~30-60 seconds |
| **Data Transfer** | -          | Only changes     | Full calendar  |

### Memory Usage

- **In-memory storage**: Events and todos kept in memory for fast API responses
- **Typical usage**: ~10-20 MB for 1000 events and 500 todos
- **Cache file**: Human-readable JSON, ~5-10 MB typical

## Sync Flow Diagram

```text
Startup
  â†“
Load Cache â”€â”€â”€â”€â†’ API Available (with cached data)
  â†“
Check Server Capabilities
  â”œâ”€â†’ Supports sync-collection?
  â”‚   â”œâ”€â†’ YES: Incremental Sync
  â”‚   â”‚   â”œâ”€â†’ Have sync token?
  â”‚   â”‚   â”‚   â”œâ”€â†’ YES: Get only changes
  â”‚   â”‚   â”‚   â””â”€â†’ NO: Fall back to full sync
  â”‚   â”‚   â”œâ”€â†’ Success? â†’ Save new sync token
  â”‚   â”‚   â””â”€â†’ Failed? â†’ Fall back to full sync
  â”‚   â”‚
  â”‚   â””â”€â†’ NO: Full Sync
  â”‚       â””â”€â†’ Query all events + todos
  â”‚
  â†“
Update Cache
  â†“
API Serves Fresh Data
  â†“
Background Sync (every 15 minutes)
  â””â”€â†’ Repeat from "Check Server Capabilities"
```

## Technical Details

### Sync Token Management

Sync tokens are stored per-calendar in the `sync_tokens` HashMap:

```rust
pub sync_tokens: std::collections::HashMap<String, String>
```

- **Key**: Calendar URL (e.g., `/calendars/user/personal/`)
- **Value**: Opaque sync token from server

Tokens are:

- **Saved** after successful incremental sync
- **Used** on next sync to get only changes
- **Cleared** when full sync is performed
- **Persisted** in cache file across restarts

### Handling Deletions

When an item is deleted on the server:

1. Server sends `is_deleted: true` in sync response
2. We match by `href` (typically ends with `{uid}.ics`)
3. Remove from both events and todos collections
4. Deletion count logged

### Conflict Resolution

**During incremental sync**:

- Items with same UID are **replaced** (server is source of truth)
- Old version removed, new version added
- ETag updated

**During full sync**:

- All items from that calendar are **removed**
- Fresh items from server are **added**
- Ensures complete consistency

## Server Compatibility

### Servers with WebDAV sync-collection

âœ… **Incremental sync available**:

- Apple iCloud Calendar
- Nextcloud
- Radicale (with sync-collection plugin)
- SOGo
- Baikal

### Servers without WebDAV sync-collection

âš ï¸ **Full sync only**:

- Google Calendar (CalDAV)
- Some legacy CalDAV servers

The system automatically detects and adapts!

## Cache Management

### Manual Cache Operations

**Clear cache** (forces full sync on next startup):

```bash
rm ~/.local/share/fred-cal/calendar_data.json  # Linux
rm ~/Library/Application\ Support/fred-cal/calendar_data.json  # macOS
```

**Inspect cache**:

```bash
cat ~/.local/share/fred-cal/calendar_data.json | jq .
```

**Check cache size**:

```bash
du -h ~/.local/share/fred-cal/
```

### Cache Validation

The cache is validated on load:

- âœ… Valid JSON â†’ Load successful
- âŒ Invalid JSON â†’ Start fresh
- âŒ Missing file â†’ Start fresh

No risk of corrupted data causing crashes!

## Best Practices

### For Small Calendars (<100 items)

- Full sync is fast enough (~1-2 seconds)
- Incremental sync still beneficial for mobile/slow connections

### For Large Calendars (1000+ items)

- **Critical**: Incremental sync reduces sync time by 90%+
- First sync after cache clear will be slow (one-time)
- Subsequent syncs are fast

### For Multiple Calendars

- Each calendar synced independently
- One slow calendar doesn't block others
- Errors in one calendar don't affect others

## Troubleshooting

### "Sync taking too long"

1. Check if server supports WebDAV sync: Look for "using incremental updates" in logs
2. Check network latency to CalDAV server
3. Consider sync interval (default 15 minutes)

### "API serving stale data"

1. Check last_sync timestamp in API responses
2. Verify background sync is running (check logs)
3. Manually trigger sync by restarting service

### "Cache file too large"

- Normal for large calendars
- Consider archiving old completed todos
- JSON is human-readable but verbose (future: could use binary format)

## Future Enhancements

Potential improvements:

1. **Binary cache format** - Faster load, smaller file
2. **Partial cache loading** - Load only recent events on startup
3. **Configurable sync interval** - Per-calendar or global
4. **Compression** - gzip cache file
5. **SQLite backend** - Better for very large calendars
6. **Multi-level cache** - Recent items in memory, old items on disk

## Monitoring

Check sync health via API:

```bash
curl http://localhost:3000/api/health
```

Response includes `last_sync` timestamp:

```json
{
  "status": "ok",
  "timestamp": "2026-01-03T19:26:30Z"
}
```

All endpoints include `last_sync` in their responses for cache freshness verification.
